{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "import deepchopper\n",
    "from deepchopper import (\n",
    "    remove_intervals_and_keep_left,\n",
    ")\n",
    "from deepchopper.utils import highlight_targets\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from rich.logging import RichHandler\n",
    "from needletail import (\n",
    "    parse_fastx_file,\n",
    "    NeedletailError,\n",
    ")\n",
    "\n",
    "import seaborn as sns\n",
    "import re\n",
    "from textwrap import wrap\n",
    "import gget\n",
    "\n",
    "FORMAT = \"%(message)s\"\n",
    "logging.basicConfig(\n",
    "    level=logging.WARN,\n",
    "    format=FORMAT,\n",
    "    handlers=[RichHandler()],\n",
    ")\n",
    "\n",
    "\n",
    "INTERNAL_THRESHOLD: float = 0.9\n",
    "OVERLAP_THRESHOLD: float = 0.4\n",
    "BLAT_THRESHOLD: float = 0.9\n",
    "MIN_MAPPING_QUALITY: int = 0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FqRecord:\n",
    "    id: str\n",
    "    seq: str\n",
    "    qual: str\n",
    "\n",
    "    def to_str(self):\n",
    "        return f\"{self.id}\n",
    "{self.seq}\n",
    "+\n",
    "{self.qual}\"\n",
    "\n",
    "\n",
    "def vis_qual_static(predict, start: int | None = None, end: int | None = None, figure_size=(20, 1)):\n",
    "    if predict.qual is None:\n",
    "        raise ValueError(\"no qual, please fetch qual first\")\n",
    "\n",
    "    start = 0 if start is None else start\n",
    "    end = len(predict.seq) if end is None else end\n",
    "\n",
    "    qual = np.array([ord(c) - 33 for c in list(predict.qual[start:end])]).reshape(1, -1)\n",
    "    seq = list(predict.seq[start:end])\n",
    "\n",
    "    # Creating the heatmap\n",
    "    fig, ax = plt.subplots(figsize=figure_size)  # Set a wide figure to accommodate the sequence\n",
    "    cax = ax.imshow(qual, aspect=\"auto\", cmap=\"viridis\")\n",
    "    cbar = plt.colorbar(cax, ax=ax, orientation=\"vertical\")\n",
    "    cbar.set_label(\"Value\")\n",
    "    # Setting up the sequence as x-axis labels\n",
    "    ax.set_xticks(np.arange(len(seq)))\n",
    "    ax.set_xticklabels(seq, rotation=90)  # Rotate labels for better readability\n",
    "    # Remove y-axis labels as there's only one row\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f\"{predict.id}: {start}-{end}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def to_fqs_record(predict, intervals: list[tuple[int, int]]):\n",
    "    if predict.qual is None:\n",
    "        raise ValueError(\"no qual, please fetch qual first\")\n",
    "\n",
    "    assert len(predict.qual) == len(predict.seq)\n",
    "\n",
    "    seqs, saved_intervals = remove_intervals_and_keep_left(predict.seq, intervals)\n",
    "    quals, saved_intervals = remove_intervals_and_keep_left(predict.qual, intervals)\n",
    "\n",
    "    assert len(seqs) == len(quals)\n",
    "    for ind, (seq, qual) in enumerate(zip(seqs, quals, strict=True)):\n",
    "        record_id = f\"@{predict.id}|{saved_intervals[ind][0], saved_intervals[ind][1]}\"\n",
    "        yield FqRecord(id=record_id, seq=seq, qual=qual)\n",
    "\n",
    "\n",
    "def smooth_and_select_intervals(\n",
    "    predict_id,\n",
    "    stats,\n",
    "    smooth_window_size: int,\n",
    "    min_interval_length: int,\n",
    "    approved_interval_nums: int = 1,\n",
    ") -> list[tuple[int, int]]:\n",
    "    chop_intervals = stats.smooth_intervals[predict_id]\n",
    "\n",
    "    results = []\n",
    "    for interval in chop_intervals:\n",
    "        if interval[1] - interval[0] > min_interval_length:\n",
    "            results.append(interval)\n",
    "\n",
    "    if len(results) > approved_interval_nums:\n",
    "        return []\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def collect_fq_records(file: Path):\n",
    "    result = {}\n",
    "    try:\n",
    "        for record in parse_fastx_file(file.as_posix()):\n",
    "            result[record.id] = record\n",
    "    except NeedletailError:\n",
    "        print(\"Invalid Fastq file\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def collect_sam_records(file: Path):\n",
    "    if not isinstance(file, Path):\n",
    "        file = Path(file)\n",
    "\n",
    "    result = {}\n",
    "    samfile = pysam.AlignmentFile(file.as_posix(), \"rb\")\n",
    "\n",
    "    for read in samfile.fetch():\n",
    "        result[read.query_name] = read\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def vis_hist_for_num_of_intervals(data, figsize=(10, 6), title=None, ax=None, set_xticks=False):\n",
    "    # Create histogram with a kernel density estimate\n",
    "    max_x = max(data) + 1\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.histplot(data, kde=True, color=\"#66c2a5\", line_kws={\"linewidth\": 2}, discrete=True)\n",
    "        if set_xticks:\n",
    "            plt.xticks(range(0, max_x, 1))\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "    else:jj\n",
    "        sns.histplot(\n",
    "            data,\n",
    "            kde=True,\n",
    "            color=\"#66c2a5\",\n",
    "            line_kws={\"linewidth\": 2},\n",
    "            discrete=True,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        if set_xticks:\n",
    "            ax.set_xticks(range(0, max_x, 1))\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "def wrap_str(ostr, width):\n",
    "    return \"\n",
    "\".join(wrap(ostr, width))\n",
    "\n",
    "\n",
    "def show_sam_record(predict, stats, sam_records):\n",
    "    seq_len = len(predict.seq)\n",
    "    txt_width = 120\n",
    "\n",
    "    print(f\"\n",
    "read id {predict.id} seq len: {seq_len}\")\n",
    "\n",
    "    smooth_intervals = stats.smooth_intervals[predict.id]\n",
    "\n",
    "    for interval in smooth_intervals:\n",
    "        quals = predict.qual_array()[interval[0] : interval[1]]\n",
    "        average_qual = sum(quals) / len(quals)\n",
    "        print(f\"smooth interval : {interval} len: {interval[1] - interval[0]}     {average_qual=}\")\n",
    "\n",
    "    highlight_targets(predict.seq, predict.prediction_region())\n",
    "    highlight_targets(predict.seq, smooth_intervals)\n",
    "\n",
    "    predict_read = sam_records.get(predict.id, None)\n",
    "    if predict_read is None:\n",
    "        print(\"the read is not map\")\n",
    "        return\n",
    "\n",
    "    if len(smooth_intervals) == 1:\n",
    "        blat_df = gget.blat(predict.seq[smooth_intervals[0][0] : smooth_intervals[0][1]])\n",
    "        if blat_df is not None:\n",
    "            print(f\"blat result:\n",
    " {blat_df.to_string()}\n",
    "\")\n",
    "\n",
    "    print(\n",
    "        f\"{predict_read.reference_id=} strand={'+' if predict_read.is_forward else '-'} {predict_read.mapping_quality=}\"\n",
    "    )\n",
    "    print(f\"{predict_read.reference_start=} {predict_read.reference_end=}\")\n",
    "    print(f\"cigar: {wrap_str(predict_read.cigarstring, txt_width)}\")\n",
    "\n",
    "    ls_len, rs_len = deepchopper.left_right_soft_clip(predict_read.cigarstring)\n",
    "    if not predict_read.is_forward:\n",
    "        ls_len, rs_len = rs_len, ls_len\n",
    "\n",
    "    print(f\"ls: 0-{ls_len}  \n",
    " {wrap_str(predict.seq[:ls_len], txt_width)}\")\n",
    "    print(f\"rs: {seq_len-rs_len}-{seq_len} \n",
    " {wrap_str(predict.seq[-rs_len:], txt_width)}\")\n",
    "\n",
    "    if predict_read.has_tag(\"SA\"):\n",
    "        print(\"has sa\")\n",
    "        chimeric_alns = predict_read.get_tag(\"SA\")[:-1].split(\";\")\n",
    "\n",
    "        for _aln in chimeric_alns:\n",
    "            (\n",
    "                chr_sa,\n",
    "                pos_sa,\n",
    "                strand_sa,\n",
    "                cigar_sa,\n",
    "                mapq_sa,\n",
    "                nm_sa,\n",
    "            ) = _aln.split(\",\")\n",
    "\n",
    "            left_mat = pat_left_s.search(cigar_sa)\n",
    "            right_mat = pat_right_s.search(cigar_sa)\n",
    "\n",
    "            l_s_len = left_mat.group(1) if left_mat else \"\"\n",
    "            r_s_len = right_mat.group(1) if right_mat else \"\"\n",
    "\n",
    "            tgt_key = f\"{predict_read.qname}\t{l_s_len=}\t{r_s_len=}\"\n",
    "\n",
    "            print(f\"chimeric : {tgt_key}\")\n",
    "\n",
    "\n",
    "def check_overlap(\n",
    "    interval1: tuple[int, int], interval2: tuple[int, int], overlap_threshold: float\n",
    ") -> bool:\n",
    "    # interval2 is predicted region\n",
    "\n",
    "    start1, end1 = interval1\n",
    "    start2, end2 = interval2\n",
    "\n",
    "    length1 = end1 - start1\n",
    "    length2 = end2 - start2\n",
    "\n",
    "    # Calculate the maximum start point and minimum end point\n",
    "    max_start = max(start1, start2)\n",
    "    min_end = min(end1, end2)\n",
    "\n",
    "    # union\n",
    "    min_start = min(start1, start2)\n",
    "    max_end = max(end1, end2)\n",
    "\n",
    "    # Calculate the overlap length\n",
    "    overlap = max(0, min_end - max_start)\n",
    "\n",
    "    divide = length2\n",
    "\n",
    "    ratio = overlap / divide\n",
    "\n",
    "    # Check if the overlap meets or exceeds the threshold\n",
    "    print(f\"compare {interval1}({length1}) {interval2}({length2}) {ratio=}\")\n",
    "    return ratio >= overlap_threshold\n",
    "\n",
    "\n",
    "def process_one_interval_parallel(\n",
    "    overlap_results,\n",
    "    whole_seq_len: int,\n",
    "    pseq,\n",
    "    pid,\n",
    "    ls_len: int,\n",
    "    rs_len: int,\n",
    "    pd_start: int,\n",
    "    pd_end: int,\n",
    "    overlap_threshold: float,\n",
    "    internal_threshold: float,\n",
    "    blat_threshold: float,\n",
    "    read_mp: int,\n",
    "    min_mapping_quality: int,\n",
    "):\n",
    "    predict_seq = pseq[pd_start:pd_end]\n",
    "    min_blat_seq_len = 20\n",
    "\n",
    "    if pd_end / whole_seq_len > internal_threshold:\n",
    "        # terminal adapter\n",
    "        # has overlap\n",
    "        if check_overlap(\n",
    "            (whole_seq_len - rs_len, whole_seq_len),\n",
    "            (pd_start, pd_end),\n",
    "            overlap_threshold,\n",
    "        ):\n",
    "            overlap_results[\"terminal_chop_sc\"].append(pid)\n",
    "        else:\n",
    "            overlap_results[\"terminal_chop_nosc\"].append(pid)\n",
    "            if len(predict_seq) < min_blat_seq_len:\n",
    "                overlap_results[\"terminal_chop_nosc_cannot_blat\"].append(pid)\n",
    "                return\n",
    "\n",
    "            blat_df = gget.blat(predict_seq)\n",
    "            if blat_df is not None:\n",
    "                print(f\"\n",
    "blat_df: {blat_df.to_string()}\n",
    "\")\n",
    "            else:\n",
    "                print(\"blat_df is None\")\n",
    "\n",
    "            if blat_df is None or (blat_df.iloc[0][\"%_aligned\"] / 100 < blat_threshold):\n",
    "                overlap_results[\"terminal_chop_nosc_noblat\"].append(pid)\n",
    "\n",
    "    else:  # internal adapter\n",
    "        flag = False\n",
    "        if ls_len != 0:\n",
    "            if check_overlap((0, ls_len), (pd_start, pd_end), overlap_threshold):\n",
    "                flag = True\n",
    "                overlap_results[\"internal_chop_sc\"].append(pid)\n",
    "\n",
    "        if rs_len != 0 and not flag:\n",
    "            if check_overlap(\n",
    "                (whole_seq_len - rs_len, whole_seq_len),\n",
    "                (pd_start, pd_end),\n",
    "                overlap_threshold,\n",
    "            ):\n",
    "                flag = True\n",
    "                overlap_results[\"internal_chop_sc\"].append(pid)\n",
    "\n",
    "        if not flag:\n",
    "            overlap_results[\"internal_chop_nosc\"].append(pid)\n",
    "\n",
    "            if len(predict_seq) < min_blat_seq_len:\n",
    "                # seq is too short, and cannot use blat\n",
    "                overlap_results[\"internal_chop_nosc_cannot_blat\"].append(pid)\n",
    "                return\n",
    "\n",
    "            blat_df = gget.blat(predict_seq)\n",
    "            if blat_df is not None:\n",
    "                print(f\"\n",
    "blat_df: {blat_df.to_string()}\n",
    "\")\n",
    "            else:\n",
    "                print(\"blat_df is None\")\n",
    "\n",
    "            if blat_df is None or (blat_df.iloc[0][\"%_aligned\"] / 100 < blat_threshold):\n",
    "                overlap_results[\"internal_chop_nosc_noblat\"].append(pid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def verify_result_with_sam_records_rs(\n",
    "    overlap_results,\n",
    "    predict,\n",
    "    stats,\n",
    "    rs_read,\n",
    "    internal_threshold: float = INTERNAL_THRESHOLD,\n",
    "    overlap_threshold: float = OVERLAP_THRESHOLD,\n",
    "    blat_threshold: float = BLAT_THRESHOLD,\n",
    "    min_mapping_quality: int = MIN_MAPPING_QUALITY,\n",
    "):\n",
    "    read_mapping_quality = rs_read.mapping_quality\n",
    "    \n",
    "    if not rs_read.is_mapped:\n",
    "        print(f\"\n",
    "the read {predict.id} is not map\")\n",
    "        overlap_results[\"unmap_read\"].append(predict.id)\n",
    "        return\n",
    "\n",
    "    if read_mapping_quality < min_mapping_quality:\n",
    "        print(f\"\n",
    "the read {predict.id}'s mapping_quality {read_mapping_quality} is low\")\n",
    "        overlap_results[\"low_mp_read\"].append(predict.id)\n",
    "        return\n",
    "\n",
    "    seq_len = len(predict.seq)\n",
    "\n",
    "    ls_len, rs_len = rs_read.left_softclip, rs_read.right_softclip\n",
    "\n",
    "    intervals = stats.smooth_intervals[predict.id]\n",
    "\n",
    "    print(\"\n",
    "\")\n",
    "    print(predict.show_info(intervals))\n",
    "\n",
    "    txt_width = 120\n",
    "    print(\n",
    "        f\"strand={'+' if rs_read.is_forward else '-'} {rs_read.mapping_quality=}\"\n",
    "    )\n",
    "    # print(f\"{predict_read.reference_start=} {predict_read.reference_end=}\")\n",
    "    print(f\"cigar: {wrap_str(rs_read.cigar, txt_width)}\")\n",
    "    print(f\"ls {ls_len}: 0-{ls_len}  \n",
    " {wrap_str(predict.seq[:ls_len], txt_width)}\")\n",
    "    print(\n",
    "        f\"rs {rs_len}: {seq_len-rs_len}-{seq_len} \n",
    " {wrap_str(predict.seq[seq_len-rs_len:seq_len], txt_width)}\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    if len(intervals) == 1:\n",
    "        # clean predict\n",
    "        start, end = intervals[0]\n",
    "        # quals = predict.qual_array()[start:end]\n",
    "        # average_qual = sum(quals) / len(quals)\n",
    "        process_one_interval_parallel(\n",
    "            overlap_results,\n",
    "            seq_len,\n",
    "            predict.seq,\n",
    "            predict.id,\n",
    "            ls_len,\n",
    "            rs_len,\n",
    "            start,\n",
    "            end,\n",
    "            overlap_threshold,\n",
    "            internal_threshold,\n",
    "            blat_threshold,\n",
    "            read_mapping_quality,\n",
    "            min_mapping_quality,\n",
    "        )\n",
    "    elif len(intervals) <= 3:\n",
    "        for interval in intervals:\n",
    "            start, end = interval\n",
    "            process_one_interval_parallel(\n",
    "                overlap_results,\n",
    "                seq_len,\n",
    "                predict.seq,\n",
    "                predict.id,\n",
    "                ls_len,\n",
    "                rs_len,\n",
    "                start,\n",
    "                end,\n",
    "                overlap_threshold,\n",
    "                internal_threshold,\n",
    "                blat_threshold,\n",
    "                read_mapping_quality,\n",
    "                min_mapping_quality,\n",
    "            )\n",
    "    else:\n",
    "        overlap_results[\"no_process\"].append(predict.id)\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def verify_result_with_sam_records_for_parallel(\n",
    "    pseq: str,\n",
    "    pid: str,\n",
    "    smooth_intervals: dict[str, list[tuple[int, int]]],\n",
    "    read_is_mapped: bool,\n",
    "    read_mapping_quality: int,\n",
    "    read_left_softclip: int,\n",
    "    read_right_softclip: int,\n",
    "    internal_threshold: float = INTERNAL_THRESHOLD,\n",
    "    overlap_threshold: float = OVERLAP_THRESHOLD,\n",
    "    blat_threshold: float = BLAT_THRESHOLD,\n",
    "    min_mapping_quality: int = MIN_MAPPING_QUALITY,\n",
    "):\n",
    "    overlap_results = defaultdict(list)\n",
    "    read_mapping_quality = read_mapping_quality\n",
    "\n",
    "    if not read_is_mapped:\n",
    "        print(f\"\n",
    "the read {pid} is not map\")\n",
    "        overlap_results[\"unmap_read\"].append(pid)\n",
    "        return overlap_results\n",
    "\n",
    "    if read_mapping_quality < min_mapping_quality:\n",
    "        print(f\"\n",
    "the read {pid}'s mapping_quality {read_mapping_quality} is low\")\n",
    "        overlap_results[\"low_mp_read\"].append(pid)\n",
    "        return overlap_results\n",
    "\n",
    "    seq_len = len(pseq)\n",
    "    ls_len, rs_len = read_left_softclip, read_right_softclip\n",
    "    intervals = smooth_intervals[pid]\n",
    "\n",
    "    if len(intervals) == 1:\n",
    "        # clean predict\n",
    "        start, end = intervals[0]\n",
    "        \n",
    "        process_one_interval_parallel(\n",
    "            overlap_results,\n",
    "            seq_len,\n",
    "            pseq,\n",
    "            pid,\n",
    "            ls_len,\n",
    "            rs_len,\n",
    "            start,\n",
    "            end,\n",
    "            overlap_threshold,\n",
    "            internal_threshold,\n",
    "            blat_threshold,\n",
    "            read_mapping_quality,\n",
    "            min_mapping_quality,\n",
    "        )\n",
    "    elif len(intervals) <= 3:\n",
    "        for interval in intervals:\n",
    "            start, end = interval\n",
    "            process_one_interval_parallel(\n",
    "                overlap_results,\n",
    "                seq_len,\n",
    "                pseq,\n",
    "                pid,\n",
    "                ls_len,\n",
    "                rs_len,\n",
    "                start,\n",
    "                end,\n",
    "                overlap_threshold,\n",
    "                internal_threshold,\n",
    "                blat_threshold,\n",
    "                read_mapping_quality,\n",
    "                min_mapping_quality,\n",
    "            )\n",
    "    else:\n",
    "        overlap_results[\"no_process\"].append(pid)\n",
    "        \n",
    "    return overlap_results\n",
    "\n",
    "\n",
    "def merge_results(results_list):\n",
    "    combined_results = defaultdict(list)\n",
    "    for single_result in results_list:\n",
    "        for key, values in single_result.items():\n",
    "            combined_results[key].extend(values)\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_result_with_sam_records(\n",
    "    overlap_results,\n",
    "    predict,\n",
    "    stats,\n",
    "    sam_records,\n",
    "    internal_threshold: float = INTERNAL_THRESHOLD,\n",
    "    overlap_threshold: float = OVERLAP_THRESHOLD,\n",
    "    blat_threshold: float = BLAT_THRESHOLD,\n",
    "    min_mapping_quality: int = MIN_MAPPING_QUALITY,\n",
    "):\n",
    "    predict_read = sam_records.get(predict.id, None)\n",
    "\n",
    "    if predict_read is None:\n",
    "        print(f\"\\nthe read {predict.id} is not map\")\n",
    "        overlap_results[\"unmap_read\"].append(predict.id)\n",
    "        return\n",
    "\n",
    "    if predict_read.mapping_quality < min_mapping_quality:\n",
    "        print(f\"\\nthe read {predict.id}'s mapping_quality {predict_read.mapping_quality} is low\")\n",
    "        overlap_results[\"low_mp_read\"].append(predict.id)\n",
    "        return\n",
    "\n",
    "    seq_len = len(predict.seq)\n",
    "\n",
    "    ls_len, rs_len = deepchopper.left_right_soft_clip(predict_read.cigarstring)\n",
    "\n",
    "    intervals = stats.smooth_intervals[predict.id]\n",
    "\n",
    "    if not predict_read.is_forward:\n",
    "        ls_len, rs_len = rs_len, ls_len\n",
    "\n",
    "    # highlight_targets(predict.seq, intervals)\n",
    "    print(\"\\n\")\n",
    "    print(predict.show_info(intervals))\n",
    "\n",
    "    txt_width = 120\n",
    "    print(\n",
    "        f\"{predict_read.reference_id=} strand={'+' if predict_read.is_forward else '-'} {predict_read.mapping_quality=}\"\n",
    "    )\n",
    "    print(f\"{predict_read.reference_start=} {predict_read.reference_end=}\")\n",
    "    print(f\"cigar: {wrap_str(predict_read.cigarstring, txt_width)}\")\n",
    "    print(f\"ls {ls_len}: 0-{ls_len}  \\n {wrap_str(predict.seq[:ls_len], txt_width)}\")\n",
    "    print(\n",
    "        f\"rs {rs_len}: {seq_len-rs_len}-{seq_len} \\n {wrap_str(predict.seq[seq_len-rs_len:seq_len], txt_width)}\"\n",
    "    )\n",
    "\n",
    "    if len(intervals) == 1:\n",
    "        # clean predict\n",
    "        start, end = intervals[0]\n",
    "        # quals = predict.qual_array()[start:end]\n",
    "        # average_qual = sum(quals) / len(quals)\n",
    "        process_one_interval_parallel(\n",
    "            overlap_results,\n",
    "            seq_len,\n",
    "            predict.seq,\n",
    "            predict.id,\n",
    "            ls_len,\n",
    "            rs_len,\n",
    "            start,\n",
    "            end,\n",
    "            overlap_threshold,\n",
    "            internal_threshold,\n",
    "            blat_threshold,\n",
    "            predict_read.mapping_quality,\n",
    "            min_mapping_quality,\n",
    "        )\n",
    "    elif len(intervals) <= 3:\n",
    "        for interval in intervals:\n",
    "            start, end = interval\n",
    "            process_one_interval_parallel(\n",
    "                overlap_results,\n",
    "                seq_len,\n",
    "                predict.seq,\n",
    "                predict.id,\n",
    "                ls_len,\n",
    "                rs_len,\n",
    "                start,\n",
    "                end,\n",
    "                overlap_threshold,\n",
    "                internal_threshold,\n",
    "                blat_threshold,\n",
    "                predict_read.mapping_quality,\n",
    "                min_mapping_quality,\n",
    "            )\n",
    "    else:\n",
    "        overlap_results[\"no_process\"].append(predict.id)\n",
    "        pass\n",
    "\n",
    "\n",
    "def vis_stats(stats, total: int):\n",
    "    # Extracting data for plotting\n",
    "    categories = [\n",
    "        \"Total Predicts\",\n",
    "        \"Total Truncated\",\n",
    "        \"Predicts with Chop\",\n",
    "        \"Smooth Predicts with Chop\",\n",
    "        \"Smooth Internal Predicts\",\n",
    "        \"Smooth Only One\",\n",
    "        \"Smooth Polya Only One\",\n",
    "    ]\n",
    "    values = [\n",
    "        stats.total_predicts,\n",
    "        stats.total_truncated,\n",
    "        len(stats.predicts_with_chop),\n",
    "        len(stats.smooth_predicts_with_chop),\n",
    "        len(stats.smooth_internal_predicts),\n",
    "        len(stats.smooth_only_one),\n",
    "        len(stats.smooth_only_one_with_ploya),\n",
    "    ]\n",
    "\n",
    "    # Creating the bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(categories, values, color=\"#66c2a5\")\n",
    "\n",
    "    # Add text annotations to the bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval + 0.5,\n",
    "            yval,\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Categories\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Statistics for {total}\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")  # Rotate category names for better visibility\n",
    "    plt.tight_layout()  # Adjust layout to make all labels visible\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_acc(data):\n",
    "    internal_chop_sc_count = len(data.get(\"internal_chop_sc\", []))\n",
    "    internal_chop_nosc_count = len(data.get(\"internal_chop_nosc\", []))\n",
    "    internal_chop_nosc_noblat_count = len(data.get(\"internal_chop_nosc_noblat\", []))\n",
    "    internal_chop_nosc_cannotblat_count = len(data.get(\"internal_chop_nosc_cannot_blat\", []))\n",
    "    total_internal = internal_chop_sc_count + internal_chop_nosc_count\n",
    "    confirmed_internal = internal_chop_sc_count + internal_chop_nosc_noblat_count\n",
    "\n",
    "    internal_acc = confirmed_internal / (total_internal)\n",
    "\n",
    "    terminal_chop_sc_count = len(data.get(\"terminal_chop_sc\", []))\n",
    "    terminal_chop_nosc_count = len(data.get(\"terminal_chop_nosc\", []))\n",
    "    terminal_chop_nosc_noblat_count = len(data.get(\"terminal_chop_nosc_noblat\", []))\n",
    "    terminal_chop_nosc_cannotblat_count = len(data.get(\"terminal_chop_nosc_cannot_blat\", []))\n",
    "    total_terminal = terminal_chop_sc_count + terminal_chop_nosc_count\n",
    "    confirmed_terminal = terminal_chop_sc_count + terminal_chop_nosc_noblat_count\n",
    "\n",
    "    terminal_acc = confirmed_terminal / (total_terminal)\n",
    "\n",
    "    total_acc = (confirmed_internal + confirmed_terminal) / (total_internal + total_terminal)\n",
    "\n",
    "    return internal_acc, terminal_acc, total_acc\n",
    "\n",
    "\n",
    "def vis_overlap_results(data):\n",
    "    import pandas as pd\n",
    "\n",
    "    internal_acc, terminal_acc, total_acc = get_acc(data)\n",
    "\n",
    "    plot_df = pd.DataFrame(\n",
    "        [(key, len(value)) for key, value in data.items()],\n",
    "        columns=[\"Category\", \"Count\"],\n",
    "    )\n",
    "\n",
    "    # Plotting the data\n",
    "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "    bars = plt.bar(plot_df[\"Category\"], plot_df[\"Count\"], color=\"skyblue\")  # Create a bar chart\n",
    "    # Add text annotations to the bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval + 0.5,\n",
    "            yval,\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Category\")  # Set the x-label\n",
    "    plt.ylabel(\"Number of Items\")  # Set the y-label\n",
    "    plt.title(\n",
    "        f\"Count of Items in Each Category {internal_acc=:.4f} {terminal_acc=:.4f} {total_acc=:.4f}\"\n",
    "    )  # Set the title\n",
    "    plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for better visibility\n",
    "    plt.tight_layout()  # Adjust layout to make room for the rotated x-labels\n",
    "    plt.show()  # Display the plot\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# overlap_results = defaultdict(list)\n",
    "\n",
    "# for p in stats.smooth_internal_predicts[:100]:\n",
    "#     verify_result_with_sam_records_rs(\n",
    "#     overlap_results,\n",
    "#     all_predicts[p],\n",
    "#     stats,\n",
    "#     rs_sam_records[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "\n",
    "- [ ] summary chop  or not chop\n",
    "- [ ] summary chop internal or terminal\n",
    "- [ ] chop only has one interval\n",
    "- [ ] summary chop interval size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sam_records = collect_sam_records(\"/projects/b1171/ylk4626/project/DeepChopper/data/eval/real_data/dorado_without_trim_fqs/VCaP.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sam_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rs_sam_records = deepchopper.read_bam_records_parallel(\n",
    "    \"/projects/b1171/ylk4626/project/DeepChopper/data/eval/real_data/dorado_without_trim_fqs/VCaP.bam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rs_sam_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chunks = [\n",
    "    Path(\"/projects/b1171/ylk4626/project/DeepChopper/tests/data/eval/chunk0\"),\n",
    "    Path(\"/projects/b1171/ylk4626/project/DeepChopper/tests/data/eval/chunk1\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_records = collect_fq_records(\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/data/eval/real_data/dorado_without_trim_fqs/VCaP.fastq\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fq_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VCaP\n",
    "hyena_results = [\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_0/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_1/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_2/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_3/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_4/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_5/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_6/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_7/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_8/predicts/0/\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/vcap/VCaP.fastq_9/predicts/0/\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batches = 100\n",
    "all_predicts = deepchopper.load_predicts_from_batch_pts(hyena_results[0], -100, max_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stats = deepchopper.py_collect_statistics_for_predicts_parallel(\n",
    "    list(all_predicts.values()),\n",
    "    smooth_window_size=21,\n",
    "    min_interval_size=10,\n",
    "    approved_interval_number=10,\n",
    "    internal_threshold=INTERNAL_THRESHOLD,\n",
    "    ploya_threshold=3,\n",
    ")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_stats(stats, len(all_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    all_predicts[stats.predicts_with_chop[0]].show_info(\n",
    "        stats.smooth_intervals[stats.predicts_with_chop[0]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prediction_number = stats.number_predicts_with_chop(all_predicts)\n",
    "smooth_prediction_number = stats.number_smooth_predicts_with_chop()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "vis_hist_for_num_of_intervals(original_prediction_number, title=\"Original Intervals\", ax=axs[0])\n",
    "vis_hist_for_num_of_intervals(smooth_prediction_number, title=\"Smooth Intervals\", ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stats.smooth_only_one_with_ploya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_oregion_size_data = stats.length_predicts_with_chop(all_predicts)\n",
    "plot_sregion_size_data = stats.lenghth_smooth_predicts_with_chop()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "vis_hist_for_num_of_intervals(\n",
    "    plot_oregion_size_data,\n",
    "    title=f\"Chop Size of clean data (original) {min(plot_oregion_size_data)}-{max(plot_oregion_size_data)}\",\n",
    "    ax=axs[0],\n",
    ")\n",
    "vis_hist_for_num_of_intervals(\n",
    "    plot_sregion_size_data,\n",
    "    title=f\"Chop Size of clean data (smooth) {min(plot_sregion_size_data)}-{max(plot_sregion_size_data)}\",\n",
    "    ax=axs[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "blat_df = gget.blat(\"TCCCTCCCACCCCCTCTCCATCATCCATATCATCCCACATCCTCCTATCCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "blat_dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predicts = len(stats.smooth_predicts_with_chop)\n",
    "overlap_results = defaultdict(list)\n",
    "idx = 0\n",
    "\n",
    "for p in stats.smoo:\n",
    "    if len(stats.smooth_intervals[p]) >= 3:\n",
    "        idx += 1\n",
    "        if idx > 100:\n",
    "            break\n",
    "\n",
    "        verify_result_with_sam_records_rs(\n",
    "            overlap_results, all_predicts[p], stats, rs_sam_records[p]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_overlap_results(overlap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"overlap_result_{max_batches}.json\", \"w\") as outfile:\n",
    "    json.dump(overlap_results, outfile, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = set(overlap_results[\"internal_chop_nosc\"]) - set(\n",
    "    overlap_results[\"internal_chop_nosc_noblat\"]\n",
    "    + overlap_results[\"internal_chop_nosc_cannot_blat\"]\n",
    ")\n",
    "\n",
    "for value in selected:\n",
    "    pd = all_predicts[value]\n",
    "\n",
    "    verify_result_with_sam_records_rs(\n",
    "        defaultdict(list),\n",
    "        pd,\n",
    "        stats,\n",
    "        rs_sam_records[value],\n",
    "        internal_threshold=INTERNAL_THRESHOLD,  # change to 0.9\n",
    "        overlap_threshold=OVERLAP_THRESHOLD,\n",
    "        blat_threshold=BLAT_THRESHOLD,\n",
    "        min_mapping_quality=MIN_MAPPING_QUALITY,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blat_cli(seq: str):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import json\n",
    "# from joblib import Parallel, delayed\n",
    "# # # Run the processing in parallel and collect all results\n",
    "# results_list = Parallel(n_jobs=1)(\n",
    "#     delayed(verify_result_with_sam_records_for_parallel)(all_predicts[p].seq,\n",
    "#                                                          all_predicts[p].id,\n",
    "#                                                          stats.smooth_intervals,\n",
    "#                                                          rs_sam_records[p].is_mapped,\n",
    "#                                                          rs_sam_records[p].mapping_quality ,\n",
    "#                                                          rs_sam_records[p].left_softclip,\n",
    "#                                                          rs_sam_records[p].right_softclip,\n",
    "#                                                          ) for p in stats.smooth_predicts_with_chop)\n",
    "# overlap_results = merge_results(results_list)\n",
    "\n",
    "# with open(\"overlap_result.json\", \"w\") as outfile:\n",
    "#     json.dump(overlap_results, outfile, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid, p in all_predicts.items():\n",
    "    p.qual = fq_records[p.id].qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = stats.smooth_predicts_with_chop\n",
    "len(ps)\n",
    "\n",
    "for p in ps[:1000]:\n",
    "    pd = all_predicts[p]\n",
    "    # show_sam_record(pd, stats, sam_records)\n",
    "    sreg = stats.smooth_intervals.get(p, [])\n",
    "    if len(sreg) > 2:\n",
    "        print(\"\\n\")\n",
    "        print(pd.show_info(sreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = stats.predicts_with_chop[0]\n",
    "vis_qual_static(\n",
    "    all_predicts[p], stats.smooth_intervals[p][0][0] - 10, stats.smooth_intervals[p][0][1] + 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stats.smooth_only_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stats.smooth_predicts_with_chop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(predcit_ids, all_predicts, stats):\n",
    "    for predict_id in predcit_ids:\n",
    "        predict = all_predicts[predict_id]\n",
    "\n",
    "        smooth_regs = stats.smooth_intervals.get(predict_id, [])\n",
    "        print(predict.show_info(smooth_regs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(\n",
    "    set(stats.smooth_predicts_with_chop) - set(stats.smooth_only_one), all_predicts, stats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# ps  = stats.smooth_predicts_with_chop\n",
    "\n",
    "# overlap_results  = defaultdict(list)\n",
    "# # ps = set(os) - set(stats.smooth_internal_predicts)\n",
    "# for p in ps:\n",
    "#     pd = all_predicts[p]\n",
    "#     # sreg = stats.smooth_intervals.get(p, [])\n",
    "#     # if len(sreg) > 2:\n",
    "#         # show_sam_record(pd, stats, sam_records)\n",
    "#         # print(\"\\n\")\n",
    "#         # print(pd.show_info(sreg))\n",
    "\n",
    "#     verify_result_with_sam_records(\n",
    "#     overlap_results,\n",
    "#     pd,\n",
    "#     stats,\n",
    "#     sam_records,\n",
    "#     internal_threshold = 0.85,\n",
    "#     overlap_threshold  = 0.4,\n",
    "#     blat_threshold  = 0.9,\n",
    "#     min_mapping_quality = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # overlap_results\n",
    "# for key, values in overlap_results.items():\n",
    "#     # if key not in [\"internal_chop_sc\",  \"terminal_chop_sc\", \"unmap_read\",\n",
    "#     #                # \"internal_chop_nosc\",\n",
    "#     #                # \"terminal_chop_nosc\"\n",
    "#     #               ]:\n",
    "#     if (key in [\"internal_chop_nosc\", \"terminal_chop_nosc\"]) and (key not in [\"internal_chop_nosc_noblat\", \"terminal_chop_nosc_noblat\"]):\n",
    "\n",
    "#         for value in values:\n",
    "#             print(f\"\\n{key}\")\n",
    "#             pd = all_predicts[value]\n",
    "\n",
    "#             verify_result_with_sam_records_rs(\n",
    "#             defaultdict(list),\n",
    "#             pd,\n",
    "#             stats,\n",
    "#             rs_sam_records[value],\n",
    "#             internal_threshold = INTERNAL_THRESHOLD, # change to 0.9\n",
    "#             overlap_threshold  = OVERLAP_THRESHOLD,\n",
    "#             blat_threshold  = BLAT_THRESHOLD,\n",
    "#             min_mapping_quality = MIN_MAPPING_QUALITY)\n",
    "\n",
    "#             # show_sam_record(pd, stats, sam_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc",
   "language": "python",
   "name": "dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
