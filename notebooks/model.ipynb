{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "import deepchopper\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "\n",
    "\n",
    "def highlight_target(seq: str, start: int, end: int, style=\"bold magenta\"):\n",
    "    text = Text(seq)\n",
    "    console = Console()\n",
    "    text.stylize(style, start, end)\n",
    "    console.print(text)\n",
    "\n",
    "\n",
    "def hightlight_predict(\n",
    "    seq: str, target_start: int, target_end: int, predict_start: int, predict_end: int\n",
    "):\n",
    "    text = Text(seq)\n",
    "    console = Console()\n",
    "\n",
    "    text.stylize(\"#adb0b1\", target_start, target_end)\n",
    "    text.stylize(\"bold magenta\", predict_start, predict_end)\n",
    "\n",
    "    console.print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform.system()='Linux'\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"{platform.system()=}\")\n",
    "if platform.system() == \"Linux\":\n",
    "    root_dir = Path(\"/projects/b1171/ylk4626/project/DeepChopper\")\n",
    "else:\n",
    "    root_dir = Path(\"/Users/ylk4626/ClionProjects/DeepChopper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: Dataset({\n",
      "    features: ['id', 'seq', 'qual', 'target'],\n",
      "    num_rows: 4000\n",
      "})\n",
      "val_dataset: Dataset({\n",
      "    features: ['id', 'seq', 'qual', 'target'],\n",
      "    num_rows: 500\n",
      "})\n",
      "test_dataset: Dataset({\n",
      "    features: ['id', 'seq', 'qual', 'target'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_file = root_dir / \"tests/data/test_input.parquet\"\n",
    "data_files = {\"train\": train_file.as_posix()}\n",
    "\n",
    "num_proc = 8\n",
    "train_dataset = load_dataset(\n",
    "    \"parquet\", data_files=data_files, num_proc=num_proc, split=\"train[:80%]\",\n",
    ").with_format(\"torch\")\n",
    "val_dataset = load_dataset(\n",
    "    \"parquet\", data_files=data_files, num_proc=num_proc, split=\"train[80%:90%]\"\n",
    ").with_format(\"torch\")\n",
    "test_dataset = load_dataset(\n",
    "    \"parquet\", data_files=data_files, num_proc=num_proc, split=\"train[90%:]\"\n",
    ").with_format(\"torch\")\n",
    "\n",
    "print(f\"train_dataset: {train_dataset}\")\n",
    "print(f\"val_dataset: {val_dataset}\")\n",
    "print(f\"test_dataset: {test_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e532cf14-74db-423e-bf6c-63a9d8cd14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd \n",
    "def show_example_for_dataset(dataset, split=None, first_examples: int=10):\n",
    "    if split is not None:\n",
    "        id = dataset[split]['id'][0:first_examples]\n",
    "        seq = dataset[split][\"seq\"][0:first_examples]\n",
    "        qual = dataset[split][\"qual\"][0:first_examples]\n",
    "        target = dataset[split][\"target\"][0:first_examples]\n",
    "    else:\n",
    "        id = dataset['id'][0:first_examples]\n",
    "        seq = dataset[\"seq\"][0:first_examples]\n",
    "        qual = dataset[\"qual\"][0:first_examples]\n",
    "        target = dataset[\"target\"][0:first_examples]\n",
    "\n",
    "\n",
    "    qual = [i.tolist() for i in qual]\n",
    "    target = [i.tolist() for i in target]\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": id,\n",
    "        \"seq\": seq,\n",
    "        \"qual\": qual,\n",
    "        \"target\": target\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b70611-e736-4569-b477-e529c7fd914e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "      <th>qual</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1065:1135|393d635c-64f0-41ed-8531-12174d8efb28...</td>\n",
       "      <td>GCAGCTATGAATGCAAGGCCACAAGGTGGATGGAAGAGTTGTGGAA...</td>\n",
       "      <td>[13, 15, 28, 28, 30, 50, 50, 50, 50, 50, 50, 5...</td>\n",
       "      <td>[1065, 1135]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573:1653|0e1e016e-02fb-4611-b1e3-6b688615e04f...</td>\n",
       "      <td>AGCGGAGAGCGGCACCATGGCCCGCGGGGCGGCGGCGGCCGCGGCC...</td>\n",
       "      <td>[21, 24, 25, 25, 50, 49, 50, 40, 42, 42, 43, 5...</td>\n",
       "      <td>[1573, 1653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607:689|29bcb833-d8d6-44d3-a0e8-5128ee173825+f...</td>\n",
       "      <td>GTAACAATACAAATGGATTTTGGGAGTGACTCAAGAAGTGAAGAAT...</td>\n",
       "      <td>[31, 43, 44, 43, 42, 43, 43, 44, 50, 50, 39, 5...</td>\n",
       "      <td>[607, 689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512:569|fea21b55-f0e1-445b-b656-565ecf669bde+5...</td>\n",
       "      <td>GTGTGAACATGCTCAACATCTCCCTTTTCTTTGGGCTGGTCATCCA...</td>\n",
       "      <td>[7, 6, 13, 30, 50, 50, 50, 50, 50, 50, 50, 42,...</td>\n",
       "      <td>[512, 569]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1128:1194|85667758-fd99-4c0a-9ca0-9fbb979bad53...</td>\n",
       "      <td>TGCGAAAGCCCCGGACTCGTGGAGTTGTTGAACGCCATGGACTCCG...</td>\n",
       "      <td>[12, 17, 20, 50, 50, 50, 45, 39, 30, 32, 33, 2...</td>\n",
       "      <td>[1128, 1194]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>504:600|8111f832-c1ae-4c0f-9a30-f5c876f28d8a+9...</td>\n",
       "      <td>GCGCAGCCATTTTGGCTTCCTGACCTTGGGCTACGGCTGACCGTTT...</td>\n",
       "      <td>[23, 27, 37, 41, 41, 50, 50, 46, 12, 11, 11, 1...</td>\n",
       "      <td>[504, 600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>673:734|a9979431-9f1f-4d52-a5bc-1400722e0b3d+3...</td>\n",
       "      <td>GGCTGCCGAAGATGGCGGAGGTGCAGGTCCACCTGGTGCTTGATGG...</td>\n",
       "      <td>[27, 32, 32, 35, 36, 38, 40, 50, 50, 50, 50, 5...</td>\n",
       "      <td>[673, 734]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>716:788|a1dd6bda-66eb-4466-adda-39297b7ee523+e...</td>\n",
       "      <td>TTGCAGCGCGATTGCCTCCGAGACCGCGAGACATACACGCAGCGAA...</td>\n",
       "      <td>[12, 21, 41, 44, 42, 22, 11, 11, 13, 15, 26, 2...</td>\n",
       "      <td>[716, 788]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>485:555|4249a00c-2aa9-4f0e-9780-2faf41d69d50+1...</td>\n",
       "      <td>GACATCTCTGACGAGGCTGCGGTGTCTGCTGCATTCCCGCTGGCTC...</td>\n",
       "      <td>[32, 36, 16, 16, 9, 10, 9, 10, 50, 48, 49, 44,...</td>\n",
       "      <td>[485, 555]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>695:776|1034f167-87a9-4d06-8857-1b26becd2242+b...</td>\n",
       "      <td>TGGGGAACAAGCAGCTGTCCCTGAGCCCAGAAGAGTATGTGTTTGC...</td>\n",
       "      <td>[12, 37, 44, 40, 42, 43, 44, 49, 50, 49, 49, 5...</td>\n",
       "      <td>[695, 776]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  1065:1135|393d635c-64f0-41ed-8531-12174d8efb28...   \n",
       "1  1573:1653|0e1e016e-02fb-4611-b1e3-6b688615e04f...   \n",
       "2  607:689|29bcb833-d8d6-44d3-a0e8-5128ee173825+f...   \n",
       "3  512:569|fea21b55-f0e1-445b-b656-565ecf669bde+5...   \n",
       "4  1128:1194|85667758-fd99-4c0a-9ca0-9fbb979bad53...   \n",
       "5  504:600|8111f832-c1ae-4c0f-9a30-f5c876f28d8a+9...   \n",
       "6  673:734|a9979431-9f1f-4d52-a5bc-1400722e0b3d+3...   \n",
       "7  716:788|a1dd6bda-66eb-4466-adda-39297b7ee523+e...   \n",
       "8  485:555|4249a00c-2aa9-4f0e-9780-2faf41d69d50+1...   \n",
       "9  695:776|1034f167-87a9-4d06-8857-1b26becd2242+b...   \n",
       "\n",
       "                                                 seq  \\\n",
       "0  GCAGCTATGAATGCAAGGCCACAAGGTGGATGGAAGAGTTGTGGAA...   \n",
       "1  AGCGGAGAGCGGCACCATGGCCCGCGGGGCGGCGGCGGCCGCGGCC...   \n",
       "2  GTAACAATACAAATGGATTTTGGGAGTGACTCAAGAAGTGAAGAAT...   \n",
       "3  GTGTGAACATGCTCAACATCTCCCTTTTCTTTGGGCTGGTCATCCA...   \n",
       "4  TGCGAAAGCCCCGGACTCGTGGAGTTGTTGAACGCCATGGACTCCG...   \n",
       "5  GCGCAGCCATTTTGGCTTCCTGACCTTGGGCTACGGCTGACCGTTT...   \n",
       "6  GGCTGCCGAAGATGGCGGAGGTGCAGGTCCACCTGGTGCTTGATGG...   \n",
       "7  TTGCAGCGCGATTGCCTCCGAGACCGCGAGACATACACGCAGCGAA...   \n",
       "8  GACATCTCTGACGAGGCTGCGGTGTCTGCTGCATTCCCGCTGGCTC...   \n",
       "9  TGGGGAACAAGCAGCTGTCCCTGAGCCCAGAAGAGTATGTGTTTGC...   \n",
       "\n",
       "                                                qual        target  \n",
       "0  [13, 15, 28, 28, 30, 50, 50, 50, 50, 50, 50, 5...  [1065, 1135]  \n",
       "1  [21, 24, 25, 25, 50, 49, 50, 40, 42, 42, 43, 5...  [1573, 1653]  \n",
       "2  [31, 43, 44, 43, 42, 43, 43, 44, 50, 50, 39, 5...    [607, 689]  \n",
       "3  [7, 6, 13, 30, 50, 50, 50, 50, 50, 50, 50, 42,...    [512, 569]  \n",
       "4  [12, 17, 20, 50, 50, 50, 45, 39, 30, 32, 33, 2...  [1128, 1194]  \n",
       "5  [23, 27, 37, 41, 41, 50, 50, 46, 12, 11, 11, 1...    [504, 600]  \n",
       "6  [27, 32, 32, 35, 36, 38, 40, 50, 50, 50, 50, 5...    [673, 734]  \n",
       "7  [12, 21, 41, 44, 42, 22, 11, 11, 13, 15, 26, 2...    [716, 788]  \n",
       "8  [32, 36, 16, 16, 9, 10, 9, 10, 50, 48, 49, 44,...    [485, 555]  \n",
       "9  [12, 37, 44, 40, 42, 43, 44, 49, 50, 49, 49, 5...    [695, 776]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_example_for_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53806a84-3ee9-44e2-ab89-1228cb434948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_target(seq, *target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hightlight_predict(seq, *target, 1070, 1120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hightlight_predict(seq, *target, 1060, 1120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Read Len of Direct RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_bam_record_len():\n",
    "    direc_rna_samples = [\"22Rv1\", \"DU145\", \"LNCaP\", \"LuCaP\", \"PC3\", \"VCaP\"]\n",
    "    data = [np.load(root_dir / f\"data/direct_rna/{p}.npy\") for p in direc_rna_samples]\n",
    "    # plt.rc('font', family='Times New Roman')\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(10, 6))\n",
    "\n",
    "    flat_axs = axs.flatten()\n",
    "\n",
    "    for i, sample in enumerate(range(len(direc_rna_samples))):\n",
    "        # Create the density plot\n",
    "        sns.kdeplot(data[i], fill=True, ax=flat_axs[i])\n",
    "        flat_axs[i].set_title(f\"Sample {sample}\")\n",
    "\n",
    "    # _ = ax1.set_xlabel('Threshold', fontsize=20)\n",
    "    # _ = ax1.set_ylabel('Length of itemsets', fontsize=20)\n",
    "\n",
    "    # ax1.legend(['Sliding window average'],fontsize=18,loc='lower left',edgecolor='k',fancybox=True)\n",
    "\n",
    "    # ax1.tick_params(axis='y', labelsize=15)\n",
    "    # ax1.tick_params(axis='x', labelsize=15\n",
    "    fig.set_size_inches(20, 20)\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.title(\"Read Length of  Direc RNA\")\n",
    "    plt.xticks(rotation=30)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_bam_record_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vis_bam_record_len(root_dir / f\"data/direct_rna/{direc_rna_samples[0]}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.remove(103380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(d2, fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data[:-800], fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "des = pd.Series(data).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# 2. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "\n",
    "def load_config_and_tokenizer_from_hyena_model(model_name):\n",
    "    max_lengths = {\n",
    "        \"hyenadna-tiny-1k-seqlen\": 1024,\n",
    "        \"hyenadna-small-32k-seqlen\": 32768,\n",
    "        \"hyenadna-medium-160k-seqlen\": 160000,\n",
    "        \"hyenadna-medium-450k-seqlen\": 450000,  # T4 up to here\n",
    "        \"hyenadna-large-1m-seqlen\": 1_000_000,  # only A100 (paid tier)\n",
    "    }\n",
    "    assert model_name in max_lengths.keys()\n",
    "    max_length = max_lengths[model_name]\n",
    "    # bfloat16 for better speed and reduced memory usage\n",
    "    model_name = f\"LongSafari/{model_name}-hf\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                              max_length=max_length, \n",
    "                                              truncation=True,  \n",
    "                                              padding=True,\n",
    "                                              trust_remote_code=True)\n",
    "    config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "    return tokenizer, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "863d3026-c063-439b-90de-79e69894bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "\n",
    "    print(f\"{predictions.shape=}\")\n",
    "    print(f\"{labels.shape=}\")\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    # Initialize lists to hold the filtered predictions and labels\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    # Filter out '-100' labels and correspondingly filter predictions\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        filtered_prediction = []\n",
    "        filtered_label = []\n",
    "\n",
    "        for p, l in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                filtered_prediction.append(p)\n",
    "                filtered_label.append(l)\n",
    "        true_predictions.append(filtered_prediction)\n",
    "        true_labels.append(filtered_label)\n",
    "\n",
    "\n",
    "    for preds, refs in zip(true_predictions, true_labels):\n",
    "        clf_metrics.add_batch(predictions=preds, references=refs)\n",
    "        \n",
    "    result = clf_metrics.compute()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb1b1cf-2a9f-4d88-b459-2bbcaf0e0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.utils import logging\n",
    "\n",
    "from transformers import PreTrainedModel\n",
    "logging.set_verbosity_info()\n",
    "logger = logging.get_logger(\"transformers\")\n",
    "\n",
    "\n",
    "class TokenClassificationHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        lin1_size: int,\n",
    "        lin2_size: int,\n",
    "        num_class: int ,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, lin1_size),\n",
    "            # nn.BatchNorm1d(lin1_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lin1_size, lin2_size),\n",
    "            # nn.BatchNorm1d(lin2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lin2_size, num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class HyenaDNAForTokenClassification(PreTrainedModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        input_size: int = 256,\n",
    "        lin1_size: int = 2048,\n",
    "        lin2_size: int = 1024,\n",
    "        num_class: int = 2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(config, trust_remote_code=True,  **kwargs)\n",
    "        self.backbone_max_length = {\n",
    "            \"hyenadna-tiny-1k-seqlen\": 1024,\n",
    "            \"hyenadna-small-32k-seqlen\": 32768,\n",
    "            \"hyenadna-medium-160k-seqlen\": 160000,\n",
    "            \"hyenadna-medium-450k-seqlen\": 450000,  # T4 up to here\n",
    "            \"hyenadna-large-1m-seqlen\": 1_000_000,  # only A100 (paid tier)\n",
    "        }\n",
    "        # assert backbone_model_name in self.backbone_max_length.keys()\n",
    "\n",
    "        self.num_class = num_class\n",
    "        self.backbone_model_name = config.name_or_path\n",
    "        self.backbone = AutoModel.from_config(config)\n",
    "        \n",
    "        self.head = TokenClassificationHead(\n",
    "            input_size=input_size,\n",
    "            lin1_size=lin1_size,\n",
    "            lin2_size=lin2_size,\n",
    "            num_class=num_class,\n",
    "        )\n",
    "\n",
    "            # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        labels: torch.Tensor,\n",
    "        # input_quals: torch.Tensor,\n",
    "        inputs_embeds: torch.FloatTensor | None = None,\n",
    "        output_hidden_states: bool | None = None,\n",
    "        return_dict: bool | None = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        # logger.info(f\"{input_ids.shape=}\")\n",
    "        # logger.info(f\"{labels.shape=}\")\n",
    "        # logger.info(f\"{input_quals.shape=}\")\n",
    "        \n",
    "        transformer_outputs = self.backbone(\n",
    "            input_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        batch_size = input_ids.shape[0]\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        # logger.info(f\"{hidden_states.shape=}\")\n",
    "        logits = self.head(hidden_states)\n",
    "\n",
    "        sequence_lengths = (\n",
    "            torch.eq(input_ids, self.backbone.config.pad_token_id).long().argmax(-1) - 1\n",
    "        ).to(logits.device)\n",
    "        labels = labels.to(logits.device)\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        # logger.info(f\"{labels.shape=}\")\n",
    "        # logger.info(f\"{labels.view(-1).shape=}\")\n",
    "        # logger.info(f\"{logits.shape=}\")\n",
    "        \n",
    "        loss = loss_fct(logits.view(-1, self.num_class), labels.view(-1))\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "befc006c-bc47-472d-850e-687b4365a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /tmp/ylk4626-jupyter//xdg_cache_home/huggingface/hub/models--LongSafari--hyenadna-small-32k-seqlen-hf/snapshots/8fe770c78eb13fe33bf81501612faeddf4d6f331/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /tmp/ylk4626-jupyter//xdg_cache_home/huggingface/hub/models--LongSafari--hyenadna-small-32k-seqlen-hf/snapshots/8fe770c78eb13fe33bf81501612faeddf4d6f331/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading configuration file config.json from cache at /tmp/ylk4626-jupyter//xdg_cache_home/huggingface/hub/models--LongSafari--hyenadna-small-32k-seqlen-hf/snapshots/8fe770c78eb13fe33bf81501612faeddf4d6f331/config.json\n",
      "loading configuration file config.json from cache at /tmp/ylk4626-jupyter//xdg_cache_home/huggingface/hub/models--LongSafari--hyenadna-small-32k-seqlen-hf/snapshots/8fe770c78eb13fe33bf81501612faeddf4d6f331/config.json\n",
      "Model config HyenaConfig {\n",
      "  \"_name_or_path\": \"LongSafari/hyenadna-small-32k-seqlen-hf\",\n",
      "  \"activation_freq\": 10,\n",
      "  \"architectures\": [\n",
      "    \"HyenaDNAForCausalLM\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"LongSafari/hyenadna-small-32k-seqlen-hf--configuration_hyena.HyenaConfig\",\n",
      "    \"AutoModel\": \"LongSafari/hyenadna-small-32k-seqlen-hf--modeling_hyena.HyenaDNAModel\",\n",
      "    \"AutoModelForCausalLM\": \"LongSafari/hyenadna-small-32k-seqlen-hf--modeling_hyena.HyenaDNAForCausalLM\",\n",
      "    \"AutoModelForSequenceClassification\": \"LongSafari/hyenadna-small-32k-seqlen-hf--modeling_hyena.HyenaDNAForSequenceClassification\"\n",
      "  },\n",
      "  \"d_inner\": 1024,\n",
      "  \"d_model\": 256,\n",
      "  \"emb_dim\": 5,\n",
      "  \"embed_dropout\": 0.1,\n",
      "  \"filter_order\": 64,\n",
      "  \"hyena_dropout\": 0.0,\n",
      "  \"hyena_filter_dropout\": 0.0,\n",
      "  \"hyena_order\": 2,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_seq_len\": 32770,\n",
      "  \"model_type\": \"hyenadna\",\n",
      "  \"n_layer\": 4,\n",
      "  \"num_inner_mlps\": 2,\n",
      "  \"pad_token_id\": 4,\n",
      "  \"pad_vocab_size_multiple\": 8,\n",
      "  \"short_filter_order\": 3,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"train_freq\": true,\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_bias\": true,\n",
      "  \"vocab_size\": 12\n",
      "}\n",
      "\n",
      "/projects/b1171/ylk4626/mambaforge/envs/deepchopper/lib/python3.10/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class 'builtins.FqEncoderOption'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/projects/b1171/ylk4626/mambaforge/envs/deepchopper/lib/python3.10/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class 'builtins.FqEncoderOption'>: builtins.FqEncoderOption has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Parameter 'function'=functools.partial(<function tokenize_and_align_labels_and_quals at 0x2b146de30550>, tokenizer=HyenaDNATokenizer(name_or_path='LongSafari/hyenadna-small-32k-seqlen-hf', vocab_size=12, model_max_length=32770, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': '[BOS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[BOS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t6: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}, max_length=32770) of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0890ae53176b48ca8eff5573c5e78c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d205f9eaa9be4a67a86cc9e08b73cd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a855ef197aa48e09a0918df3a690216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for LongSafari/hyenadna-small-32k-seqlen-hf contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/LongSafari/hyenadna-small-32k-seqlen-hf.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def tokenize_and_align_labels_and_quals(data, tokenizer, max_length, pad_qual=0, pad_label=-100):\n",
    "    tokenized_inputs = tokenizer(data[\"seq\"], max_length=max_length, truncation=True, padding=True)\n",
    "    labels = torch.tensor(deepchopper.vertorize_target(*data[\"target\"], len(data[\"seq\"])) + [pad_label])\n",
    "    quals = torch.cat((data[\"qual\"], torch.tensor([pad_qual])))\n",
    "    tokenized_inputs.update({\"labels\": labels, \"input_quals\": quals})\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "def tokenize_dataset(dataset, tokenizer, max_length):\n",
    "    return dataset.map(\n",
    "    partial(tokenize_and_align_labels_and_quals, \n",
    "            tokenizer=tokenizer, max_length=max_length)).remove_columns([\"id\", \"seq\", \"qual\", \"target\"])\n",
    "\n",
    "\n",
    "model_name = \"hyenadna-small-32k-seqlen\" \n",
    "tokenizer, model_config = load_config_and_tokenizer_from_hyena_model(model_name)\n",
    "\n",
    "\n",
    "tokenize_train_dataset =   tokenize_dataset(train_dataset, tokenizer, max_length=model_config.max_seq_len)\n",
    "tokenize_val_dataset   =   tokenize_dataset(val_dataset, tokenizer, max_length=model_config.max_seq_len)\n",
    "tokenize_test_dataset  =   tokenize_dataset(test_dataset, tokenizer, max_length=model_config.max_seq_len)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "model = HyenaDNAForTokenClassification(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9ea260-7fc2-4408-9f4d-fa91aa0cda3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels', 'input_quals'],\n",
       "    num_rows: 4000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb78a523-72c1-46b1-b4ee-cd7a4e4c1dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "The following columns in the training set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 4,000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10,000\n",
      "  Number of trainable parameters = 5,904,130\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 43:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.985859</td>\n",
       "      <td>0.760180</td>\n",
       "      <td>0.756148</td>\n",
       "      <td>0.764256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.029720</td>\n",
       "      <td>0.990008</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.879472</td>\n",
       "      <td>0.763969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>0.833839</td>\n",
       "      <td>0.929940</td>\n",
       "      <td>0.755741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.993990</td>\n",
       "      <td>0.895101</td>\n",
       "      <td>0.916772</td>\n",
       "      <td>0.874430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>0.994634</td>\n",
       "      <td>0.906134</td>\n",
       "      <td>0.930223</td>\n",
       "      <td>0.883260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.013045</td>\n",
       "      <td>0.995111</td>\n",
       "      <td>0.917327</td>\n",
       "      <td>0.909888</td>\n",
       "      <td>0.924887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.996150</td>\n",
       "      <td>0.934472</td>\n",
       "      <td>0.932910</td>\n",
       "      <td>0.936040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.996029</td>\n",
       "      <td>0.930226</td>\n",
       "      <td>0.959388</td>\n",
       "      <td>0.902784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.945566</td>\n",
       "      <td>0.943434</td>\n",
       "      <td>0.947708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.948785</td>\n",
       "      <td>0.948486</td>\n",
       "      <td>0.949084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.997086</td>\n",
       "      <td>0.950452</td>\n",
       "      <td>0.947877</td>\n",
       "      <td>0.953040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.997042</td>\n",
       "      <td>0.950687</td>\n",
       "      <td>0.930113</td>\n",
       "      <td>0.972191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.951042</td>\n",
       "      <td>0.959365</td>\n",
       "      <td>0.942863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.997416</td>\n",
       "      <td>0.955902</td>\n",
       "      <td>0.956643</td>\n",
       "      <td>0.955162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.997601</td>\n",
       "      <td>0.959085</td>\n",
       "      <td>0.959195</td>\n",
       "      <td>0.958975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.997544</td>\n",
       "      <td>0.958488</td>\n",
       "      <td>0.950344</td>\n",
       "      <td>0.966773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.997461</td>\n",
       "      <td>0.956385</td>\n",
       "      <td>0.963622</td>\n",
       "      <td>0.949256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.997612</td>\n",
       "      <td>0.959643</td>\n",
       "      <td>0.951396</td>\n",
       "      <td>0.968034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.997654</td>\n",
       "      <td>0.959991</td>\n",
       "      <td>0.960376</td>\n",
       "      <td>0.959606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.997728</td>\n",
       "      <td>0.961350</td>\n",
       "      <td>0.959319</td>\n",
       "      <td>0.963390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory hyena_model/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Saving model checkpoint to hyena_model/checkpoint-500\n",
      "Configuration saved in hyena_model/checkpoint-500/config.json\n",
      "Model weights saved in hyena_model/checkpoint-500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory hyena_model/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Saving model checkpoint to hyena_model/checkpoint-1000\n",
      "Configuration saved in hyena_model/checkpoint-1000/config.json\n",
      "Model weights saved in hyena_model/checkpoint-1000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-1500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-1500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-1500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-2000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-2000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-2000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-2000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-2500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-2500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-2500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-3000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-3000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-3000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-3500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-3500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-3500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-3500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-4000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-4000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-4000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-4000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-4500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-4500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-4500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-4500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-5000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-5000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-5000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-5000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-5500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-5500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-5500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-5500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-6000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-6000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-6000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-6000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-6500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-6500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-6500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-6500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-7000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-7000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-7000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-7000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-7500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-7500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-7500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-7500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-8000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-8000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-8000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-8000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-8500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-8500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-8500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-8500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-9000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-9000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-9000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-9000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-9500\n",
      "Configuration saved in hyena_model/tmp-checkpoint-9500/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-9500/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-9500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to hyena_model/tmp-checkpoint-10000\n",
      "Configuration saved in hyena_model/tmp-checkpoint-10000/config.json\n",
      "Model weights saved in hyena_model/tmp-checkpoint-10000/model.safetensors\n",
      "tokenizer config file saved in hyena_model/tmp-checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in hyena_model/tmp-checkpoint-10000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from hyena_model/checkpoint-10000 (score: 0.006006535608321428).\n",
      "There were missing keys in the checkpoint model loaded: ['backbone.backbone.layers.0.mixer.filter_fn.implicit_filter.3.freq', 'backbone.backbone.layers.0.mixer.filter_fn.implicit_filter.5.freq', 'backbone.backbone.layers.1.mixer.filter_fn.implicit_filter.3.freq', 'backbone.backbone.layers.1.mixer.filter_fn.implicit_filter.5.freq', 'backbone.backbone.layers.2.mixer.filter_fn.implicit_filter.3.freq', 'backbone.backbone.layers.2.mixer.filter_fn.implicit_filter.5.freq', 'backbone.backbone.layers.3.mixer.filter_fn.implicit_filter.3.freq', 'backbone.backbone.layers.3.mixer.filter_fn.implicit_filter.5.freq'].\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"hyena_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    torch_compile = False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenize_train_dataset,\n",
    "    eval_dataset=tokenize_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31393c22-acaf-43be-a373-b5256aea3e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.07240175819396973, metrics={'train_runtime': 268.7689, 'train_samples_per_second': 29.765, 'train_steps_per_second': 3.721, 'total_flos': 1283560420746240.0, 'train_loss': 0.07240175819396973, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46fb35a3-c737-40f5-8362-ff24c4551ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9652</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9652\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.006006535608321428,\n",
       " 'eval_accuracy': 0.9977284115022077,\n",
       " 'eval_f1': 0.9613503075382634,\n",
       " 'eval_precision': 0.9593194210511291,\n",
       " 'eval_recall': 0.9633898110719302,\n",
       " 'eval_runtime': 57.5015,\n",
       " 'eval_samples_per_second': 8.695,\n",
       " 'eval_steps_per_second': 1.096,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d47fe345-7c02-49ce-b0d6-79638549b196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `HyenaDNAForTokenClassification.forward` and have been ignored: input_quals. If input_quals are not expected by `HyenaDNAForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">predictions.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9524</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "predictions.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9524\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">labels.<span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9524</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "labels.\u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m9524\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicts = trainer.predict(tokenize_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab040620-e83f-42de-97cf-7d6c271f6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_predict(predictions, labels):\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    # Initialize lists to hold the filtered predictions and labels\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    # Filter out '-100' labels and correspondingly filter predictions\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        filtered_prediction = []\n",
    "        filtered_label = []\n",
    "\n",
    "        for p, l in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                filtered_prediction.append(p)\n",
    "                filtered_label.append(l)\n",
    "        true_predictions.append(filtered_prediction)\n",
    "        true_labels.append(filtered_label)\n",
    "\n",
    "\n",
    "    return true_predictions, true_labels\n",
    "\n",
    "def alignment_predict(prediction, label):\n",
    "    import textwrap\n",
    "    prediction_str = \"\".join(map(lambda x : str(x), prediction))\n",
    "    label_str = \"\".join(map(lambda x : str(x), label))\n",
    "    front2 = \"L:\"\n",
    "    front1 = \"P:\"\n",
    "    for l1, l2 in zip(textwrap.wrap(prediction_str), textwrap.wrap(label_str)):\n",
    "        ss = f\"{front1}{l1}\\n{front2}{l2}\"\n",
    "        print(ss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27a6d446-f3d0-4fe2-9268-ecc4050439a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100, -100, -100, ..., -100, -100, -100],\n",
       "       [-100, -100, -100, ..., -100, -100, -100],\n",
       "       [-100, -100, -100, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., -100, -100, -100],\n",
       "       [-100, -100, -100, ..., -100, -100, -100],\n",
       "       [-100, -100, -100, ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e35e5b0a-c0e4-4d23-a30a-8db33d71a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions, true_labels = summary_predict(predicts[0], predicts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d12820b9-2848-4097-97d4-f79e41743cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000111111111111111111</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000011111111111111111111</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000111111111111111111\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000011111111111111111111\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1111111111111110001111111111111111111111000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1111111111111111111111111111111111111110000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m1111111111111110001111111111111111111111000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m1111111111111111111111111111111111111110000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000000000000000000000000000000000000000000000000000000000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
       "L:\u001b[1;36m0000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">P:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">00000000000000000</span>\n",
       "L:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">00000000000000000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "P:\u001b[1;36m00000000000000000\u001b[0m\n",
       "L:\u001b[1;36m00000000000000000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alignment_predict(true_predictions[4], true_labels[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fcd835-aaf7-45c9-8ac1-97cb23b76850",
   "metadata": {},
   "source": [
    "# Train with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b9bf3-6dd5-4658-8485-f649e7001716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080ece2-8872-4d69-bd2a-3c9fec44a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01530095-3e3c-4013-a3b3-d372571d2e1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train with native model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "925282c9-4c82-4f04-a874-ef81507c45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from einops import rearrange\n",
    "from typing import Optional\n",
    "from functools import partial\n",
    "from torch import Tensor\n",
    "from torchvision.ops import StochasticDepth\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2ad67-0e49-414a-bbf3-e3e0c351daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Hyena layer\n",
    "\n",
    "\n",
    "def fftconv(u, k, D):\n",
    "    \"\"\"\n",
    "    We apply a convolution through the fourier domain (from the Convolution Theorem)\n",
    "\n",
    "    \"\"\"\n",
    "    seqlen = u.shape[-1]\n",
    "    fft_size = 2 * seqlen\n",
    "\n",
    "    k_f = torch.fft.rfft(k, n=fft_size) / fft_size\n",
    "    u_f = torch.fft.rfft(u.to(dtype=k.dtype), n=fft_size)\n",
    "\n",
    "    if len(u.shape) > 3: k_f = k_f.unsqueeze(1)\n",
    "    y = torch.fft.irfft(u_f * k_f, n=fft_size, norm='forward')[..., :seqlen]\n",
    "\n",
    "    out = y + u * D.unsqueeze(-1)\n",
    "    return out.to(dtype=u.dtype)\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def mul_sum(q, y):\n",
    "    return (q * y).sum(dim=1)\n",
    "\n",
    "class OptimModule(nn.Module):\n",
    "    \"\"\" Interface for Module that allows registering buffers/parameters with configurable optimizer hyperparameters \"\"\"\n",
    "\n",
    "    def register(self, name, tensor, lr=None, wd=0.0):\n",
    "        \"\"\"Register a tensor with a configurable learning rate and 0 weight decay\"\"\"\n",
    "\n",
    "        if lr == 0.0:\n",
    "            self.register_buffer(name, tensor)\n",
    "        else:\n",
    "            self.register_parameter(name, nn.Parameter(tensor))\n",
    "\n",
    "            optim = {}\n",
    "            if lr is not None: optim[\"lr\"] = lr\n",
    "            if wd is not None: optim[\"weight_decay\"] = wd\n",
    "            setattr(getattr(self, name), \"_optim\", optim)\n",
    "\n",
    "\n",
    "class Sin(nn.Module):\n",
    "    \"\"\"The Sin activation function for the Hyena Filter function.\"\"\"\n",
    "    def __init__(self, dim, w=10, train_freq=True):\n",
    "        super().__init__()\n",
    "        self.freq = nn.Parameter(w * torch.ones(1, dim)) if train_freq else w * torch.ones(1, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.freq * x)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(OptimModule):\n",
    "    def __init__(self, emb_dim: int, seq_len: int, lr_pos_emb: float=1e-5, **kwargs):\n",
    "        \"\"\"Complex exponential positional embeddings for Hyena filters.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        # The time embedding fed to the filteres is normalized so that t_f = 1\n",
    "        t = torch.linspace(0, 1, self.seq_len)[None, :, None] # 1, L, 1\n",
    "\n",
    "        if emb_dim > 1:\n",
    "            bands = (emb_dim - 1) // 2\n",
    "        # To compute the right embeddings we use the \"proper\" linspace\n",
    "        t_rescaled = torch.linspace(0, seq_len - 1, seq_len)[None, :, None]\n",
    "        w = 2 * math.pi * t_rescaled / seq_len # 1, L, 1\n",
    "\n",
    "        f = torch.linspace(1e-4, bands - 1, bands)[None, None]\n",
    "        z = torch.exp(-1j * f * w)\n",
    "        z = torch.cat([t, z.real, z.imag], dim=-1)\n",
    "        self.register(\"z\", z, lr=lr_pos_emb)\n",
    "        self.register(\"t\", t, lr=0.0)\n",
    "\n",
    "    def forward(self, L):\n",
    "        return self.z[:, :L], self.t[:, :L]\n",
    "\n",
    "\n",
    "class ExponentialModulation(OptimModule):\n",
    "    \"\"\"The window function applied to the output of the (MLP) filter function.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        fast_decay_pct=0.3,\n",
    "        slow_decay_pct=1.5,\n",
    "        target=1e-2,\n",
    "        modulation_lr=0.0,\n",
    "        modulate: bool=True,\n",
    "        shift: float = 0.05,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.modulate = modulate\n",
    "        self.shift = shift\n",
    "        max_decay = math.log(target) / fast_decay_pct\n",
    "        min_decay = math.log(target) / slow_decay_pct\n",
    "        deltas = torch.linspace(min_decay, max_decay, d_model)[None, None]\n",
    "        self.register(\"deltas\", deltas, lr=modulation_lr)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        if self.modulate:\n",
    "            decay = torch.exp(-t * self.deltas.abs())\n",
    "            x = x * (decay + self.shift)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HyenaFilter(OptimModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            d_model,\n",
    "            emb_dim=3, # dim of input to MLP, augments with positional encoding\n",
    "            order=16, # width of the implicit MLP\n",
    "            fused_fft_conv=False,\n",
    "            seq_len=1024,\n",
    "            lr=1e-3,\n",
    "            lr_pos_emb=1e-5,\n",
    "            dropout=0.0,\n",
    "            w=1, # frequency of periodic activations\n",
    "            wd=0, # weight decay of kernel parameters\n",
    "            bias=True,\n",
    "            num_inner_mlps=2,\n",
    "            normalized=False,\n",
    "            **kwargs\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Implicit long filter with modulation.\n",
    "\n",
    "        Args:\n",
    "            d_model: number of channels in the input\n",
    "            emb_dim: dimension of the positional encoding (`emb_dim` - 1) // 2 is the number of bands\n",
    "            order: width of the FFN\n",
    "            num_inner_mlps: number of inner linear layers inside filter MLP\n",
    "\n",
    "        Note:\n",
    "            filter_dropout is not implemented\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.use_bias = bias\n",
    "        self.fused_fft_conv = fused_fft_conv\n",
    "        self.bias = nn.Parameter(torch.randn(self.d_model))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        act = Sin(dim=order, w=w)\n",
    "        self.emb_dim = emb_dim\n",
    "        assert emb_dim % 2 != 0 and emb_dim >= 3, \"emb_dim must be odd and greater or equal to 3 (time, sine and cosine)\"\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.pos_emb = PositionalEmbedding(emb_dim, seq_len, lr_pos_emb)\n",
    "\n",
    "        self.implicit_filter = nn.Sequential(\n",
    "            nn.Linear(emb_dim, order),\n",
    "            act,\n",
    "        )\n",
    "        for i in range(num_inner_mlps):\n",
    "            self.implicit_filter.append(nn.Linear(order, order))\n",
    "            self.implicit_filter.append(act)\n",
    "\n",
    "        self.implicit_filter.append(nn.Linear(order, d_model, bias=False))\n",
    "\n",
    "        self.modulation = ExponentialModulation(d_model, **kwargs)\n",
    "\n",
    "        self.normalized = normalized\n",
    "        for c in self.implicit_filter.children():\n",
    "            for name, v in c.state_dict().items():\n",
    "                optim = {\"weight_decay\": wd, \"lr\": lr}\n",
    "                setattr(getattr(c, name), \"_optim\", optim)\n",
    "\n",
    "    def filter(self, L, *args, **kwargs):\n",
    "        z, t = self.pos_emb(L)\n",
    "        h = self.implicit_filter(z)\n",
    "        h = self.modulation(t, h)\n",
    "        return h\n",
    "\n",
    "    def forward(self, x, L, k=None, bias=None, *args, **kwargs):\n",
    "        if k is None: k = self.filter(L)\n",
    "\n",
    "        # Ensure compatibility with filters that return a tuple\n",
    "        k = k[0] if type(k) is tuple else k\n",
    "\n",
    "        y = fftconv(x, k, bias)\n",
    "        return y\n",
    "\n",
    "\n",
    "class HyenaOperator(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            d_model,\n",
    "            l_max,\n",
    "            order=2,\n",
    "            filter_order=64,\n",
    "            dropout=0.0,\n",
    "            filter_dropout=0.0,\n",
    "            **filter_args,\n",
    "        ):\n",
    "        r\"\"\"\n",
    "        Hyena operator described in the paper https://arxiv.org/pdf/2302.10866.pdf\n",
    "\n",
    "        Args:\n",
    "            d_model (int): Dimension of the input and output embeddings (width of the layer)\n",
    "            l_max: (int): Maximum input sequence length. Defaults to None\n",
    "            order: (int): Depth of the Hyena recurrence. Defaults to 2\n",
    "            dropout: (float): Dropout probability. Defaults to 0.0\n",
    "            filter_dropout: (float): Dropout probability for the filter. Defaults to 0.0\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.l_max = l_max\n",
    "        self.order = order\n",
    "        inner_width = d_model * (order + 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.in_proj = nn.Linear(d_model, inner_width)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.short_filter = nn.Conv1d(\n",
    "            inner_width,\n",
    "            inner_width,\n",
    "            3,\n",
    "            padding=2,\n",
    "            groups=inner_width\n",
    "        )\n",
    "        self.filter_fn = HyenaFilter(\n",
    "            d_model * (order - 1),\n",
    "            order=filter_order,\n",
    "            seq_len=l_max,\n",
    "            channels=1,\n",
    "            dropout=filter_dropout,\n",
    "            **filter_args\n",
    "        )\n",
    "\n",
    "    def forward(self, u, *args, **kwargs):\n",
    "        l = u.size(-2)\n",
    "        l_filter = min(l, self.l_max)\n",
    "        u = self.in_proj(u)\n",
    "        u = rearrange(u, 'b l d -> b d l')\n",
    "\n",
    "        uc = self.short_filter(u)[...,:l_filter]\n",
    "        *x, v = uc.split(self.d_model, dim=1)\n",
    "\n",
    "        k = self.filter_fn.filter(l_filter)[0]\n",
    "        k = rearrange(k, 'l (o d) -> o d l', o=self.order - 1)\n",
    "        bias = rearrange(self.filter_fn.bias, '(o d) -> o d', o=self.order - 1)\n",
    "\n",
    "        for o, x_i in enumerate(reversed(x[1:])):\n",
    "            v = self.dropout(v * x_i)\n",
    "            v = self.filter_fn(v, l_filter, k=k[o], bias=bias[o])\n",
    "\n",
    "        y = rearrange(v * x[0], 'b d l -> b l d')\n",
    "\n",
    "        y = self.out_proj(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6613d2e-d256-4c3e-9892-996fe1c08838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title MLP layer\n",
    "\n",
    "\"\"\"\n",
    "The MLP layer after the mixer layer (HyenaOperator).\n",
    "\"\"\"\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, activation=F.gelu,\n",
    "                 return_residual=False, device=None, dtype=None):\n",
    "        \"\"\"\n",
    "        From https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/modules/mlp.py\n",
    "        \"\"\"\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.return_residual = return_residual\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features, **factory_kwargs)\n",
    "        self.activation = activation\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features, **factory_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.fc2(y)\n",
    "        return y if not self.return_residual else (y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7ad914-c847-40e1-9ac7-f62e1a2ef1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Block layer (Hyena + MLP layers)\n",
    "\n",
    "\"\"\"\n",
    "A block consists of a Mixer layer (Hyena or attention), and a MLP layer.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class LinearResidual(nn.Linear):\n",
    "    \"\"\"Wrap nn.Linear to return the residual as well. For compatibility with FusedDense.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return super().forward(input), input\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, mixer_cls=None, mlp_cls=None, norm_cls=nn.LayerNorm,\n",
    "                 dropout_cls=nn.Dropout, prenorm=True, resid_dropout1=0., resid_dropout2=0.,\n",
    "                 drop_path1=0., drop_path2=0.,\n",
    "                 return_residual=False,\n",
    "                 residual_in_fp32=False):\n",
    "        \"\"\"\n",
    "        From https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/modules/block.py\n",
    "        For prenorm=True, this Block has a slightly different structure compared to a regular\n",
    "        prenorm Transformer block.\n",
    "        The standard block is: LN -> MHA -> Dropout -> Add -> LN -> MLP -> Dropout -> Add.\n",
    "        [Ref: https://arxiv.org/abs/2002.04745]\n",
    "        Here we have: Dropout -> Add -> LN -> MHA -> Dropout -> Add -> LN -> MLP, returning both\n",
    "        the hidden_states (output of the MLP) and the residual.\n",
    "        This is for performance reasons, as we can fuse the dropout, add and LayerNorm.\n",
    "        The residual needs to be provided (except for the very first block).\n",
    "        For prenorm=False, this Block has the same structure as a regular postnorm Transformer\n",
    "        block: MHA -> Dropout -> Add -> LN -> MLP -> Dropout -> Add -> LN.\n",
    "        return_residual: whether each of the sub-layers (mixer and mlp) will return the residual.\n",
    "        This is for performance reason: for post-norm architecture, returning the input allows us\n",
    "        to fuse the backward of nn.Linear with the residual connection.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.prenorm = prenorm\n",
    "        self.return_residual = return_residual\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "        if self.residual_in_fp32:\n",
    "            assert self.prenorm, 'residual_in_fp32 is only compatible with prenorm=True'\n",
    "        if mixer_cls is None:\n",
    "            mixer_cls = partial(MHA, num_heads=dim // 64)\n",
    "        if mlp_cls is None:\n",
    "            mlp_cls = partial(Mlp, hidden_features=4 * dim)\n",
    "        self.mixer = mixer_cls()\n",
    "        self.dropout1 = dropout_cls(resid_dropout1)\n",
    "        self.drop_path1 = StochasticDepth(drop_path1, mode='row')\n",
    "        self.norm1 = norm_cls(dim)\n",
    "        self.mlp = mlp_cls(dim)\n",
    "        if not isinstance(self.mlp, nn.Identity):\n",
    "            self.dropout2 = dropout_cls(resid_dropout2)\n",
    "            self.drop_path2 = StochasticDepth(drop_path2, mode='row')\n",
    "            self.norm2 = norm_cls(dim)\n",
    "\n",
    "    def forward(self, hidden_states, residual = None,\n",
    "                mixer_subset=None, mixer_kwargs=None):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "        Args:\n",
    "            hidden_states: the sequence to the encoder layer (required).\n",
    "            residual: if postnorm, residual=None, If prenorm, hidden_states = Attn/MLP(LN(residual))\n",
    "            mixer_subset: for cross-attention only. If not None, will take a subset of x\n",
    "                before applying the query projection. Useful for e.g., ViT where we only care\n",
    "                about the CLS token in the last layer.\n",
    "        \"\"\"\n",
    "        if self.prenorm:\n",
    "            dropped = self.drop_path1(self.dropout1(hidden_states))\n",
    "            residual = (dropped + residual) if residual is not None else dropped\n",
    "            hidden_states = self.norm1(residual.to(dtype=self.norm1.weight.dtype))\n",
    "            if self.residual_in_fp32:\n",
    "                residual = residual.to(torch.float32)\n",
    "            if mixer_kwargs is None:\n",
    "                mixer_kwargs = {}\n",
    "            if mixer_subset is not None:\n",
    "                mixer_kwargs['mixer_subset'] = mixer_subset\n",
    "            hidden_states = self.mixer(hidden_states, **mixer_kwargs)\n",
    "            if mixer_subset is not None:\n",
    "                residual = residual[:, mixer_subset]\n",
    "            if not isinstance(self.mlp, nn.Identity):\n",
    "                dropped = self.drop_path2(self.dropout2(hidden_states))\n",
    "                residual = (dropped + residual) if residual is not None else dropped\n",
    "                hidden_states = self.norm2(residual.to(dtype=self.norm2.weight.dtype))\n",
    "                if self.residual_in_fp32:\n",
    "                    residual = residual.to(torch.float32)\n",
    "\n",
    "                hidden_states = self.mlp(hidden_states)\n",
    "            return hidden_states, residual\n",
    "        else:\n",
    "            assert residual is None\n",
    "            mixer_out = self.mixer(\n",
    "                hidden_states, **(mixer_kwargs if mixer_kwargs is not None else {})\n",
    "            )\n",
    "            if self.return_residual:  # mixer out is actually a pair here\n",
    "                mixer_out, hidden_states = mixer_out\n",
    "\n",
    "            hidden_states = self.norm1((self.drop_path1(self.dropout1(mixer_out))\n",
    "                                        + hidden_states).to(dtype=self.norm1.weight.dtype))\n",
    "\n",
    "            if not isinstance(self.mlp, nn.Identity):\n",
    "                mlp_out = self.mlp(hidden_states)\n",
    "                if self.return_residual:  # mlp out is actually a pair here\n",
    "                    mlp_out, hidden_states = mlp_out\n",
    "\n",
    "                hidden_states = self.norm2((self.drop_path2(self.dropout2(mlp_out))\n",
    "                                            + hidden_states).to(dtype=self.norm2.weight.dtype))\n",
    "\n",
    "            return hidden_states\n",
    "\n",
    "def create_mixer_cls(layer=None,\n",
    "                     attn_layer_idx=None, attn_cfg=None, layer_idx=None,\n",
    "                     device=None, dtype=None):\n",
    "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "    if attn_layer_idx is not None and layer_idx in attn_layer_idx:\n",
    "        causal = True if attn_cfg is None else attn_cfg.pop('causal', True)\n",
    "\n",
    "        mha_cls = MHA\n",
    "\n",
    "        mixer_cls = partial(mha_cls, causal=causal, layer_idx=layer_idx,\n",
    "                            **(attn_cfg if attn_cfg is not None else {}),**factory_kwargs)\n",
    "    else:\n",
    "        # mixer_cls = instantiate(registry.layer, layer, partial=True, layer_idx=layer_idx, **factory_kwargs)\n",
    "\n",
    "        mixer_cls = partial(HyenaOperator, **layer)\n",
    "\n",
    "    return mixer_cls\n",
    "\n",
    "def create_mlp_cls(d_model, d_inner=None, device=None, dtype=None):\n",
    "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "    inner_dim = d_inner if d_inner is not None else 4 * d_model\n",
    "\n",
    "    mlp_cls = partial(Mlp, hidden_features=inner_dim,\n",
    "                          activation=partial(F.gelu, approximate='tanh'), **factory_kwargs)\n",
    "\n",
    "    return mlp_cls\n",
    "\n",
    "\n",
    "def create_block(d_model, d_inner=None,\n",
    "                 layer=None, attn_layer_idx=None,\n",
    "                 attn_cfg=None, layer_norm_epsilon=1e-5,\n",
    "                 resid_dropout1=0.0, resid_dropout2=0.0, residual_in_fp32=False,\n",
    "                 layer_idx=None,\n",
    "                 device=None, dtype=None):\n",
    "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "    mixer_cls = create_mixer_cls(layer=layer,\n",
    "                                 attn_layer_idx=attn_layer_idx,\n",
    "                                 attn_cfg=attn_cfg, layer_idx=layer_idx,\n",
    "                                 **factory_kwargs)\n",
    "    mlp_cls = create_mlp_cls(d_model, d_inner=d_inner,\n",
    "                             **factory_kwargs)\n",
    "    norm_cls = partial(nn.LayerNorm, eps=layer_norm_epsilon, **factory_kwargs)\n",
    "    block = Block(d_model, mixer_cls, mlp_cls, norm_cls=norm_cls,\n",
    "                  prenorm=True, resid_dropout1=resid_dropout1, resid_dropout2=resid_dropout2,residual_in_fp32=residual_in_fp32)\n",
    "    block.layer_idx = layer_idx\n",
    "    return block\n",
    "\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/c28d04e9e252a1a099944e325685f14d242ecdcd/src/transformers/models/gpt2/modeling_gpt2.py#L454\n",
    "def _init_weights(module, n_layer, initializer_range=0.02, rescale_prenorm_residual=True,\n",
    "                  glu_act=False):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.normal_(module.weight, std=initializer_range)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        nn.init.normal_(module.weight, std=initializer_range)\n",
    "\n",
    "    if rescale_prenorm_residual:\n",
    "        # Reinitialize selected weights subject to the OpenAI GPT-2 Paper Scheme:\n",
    "        #   > A modified initialization which accounts for the accumulation on the residual path with model depth. Scale\n",
    "        #   > the weights of residual layers at initialization by a factor of 1/√N where N is the # of residual layers.\n",
    "        #   >   -- GPT-2 :: https://openai.com/blog/better-language-models/\n",
    "        #\n",
    "        # Reference (Megatron-LM): https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py\n",
    "        for name, p in module.named_parameters():\n",
    "            if name in [\"out_proj.weight\", \"fc2.weight\"]:\n",
    "                # Special Scaled Initialization --> There are 2 Layer Norms per Transformer Block\n",
    "                nn.init.normal_(p, mean=0.0, std=initializer_range / math.sqrt(2 * n_layer))\n",
    "            # If using GLU activation for now, we scale the std by 2\n",
    "            elif name in [\"output_linear.0.weight\"]:\n",
    "                # Special Scaled Initialization --> There are 2 Layer Norms per Transformer Block\n",
    "                if not glu_act:\n",
    "                    nn.init.normal_(p, mean=0.0, std=initializer_range / math.sqrt(2 * n_layer))\n",
    "                else:\n",
    "                    out_features = p.shape[0]\n",
    "                    # Multiplying the first half of the matrix by 2 since sigmoid scales it down by 0.5\n",
    "                    # on average.\n",
    "                    nn.init.normal_(p[:out_features // 2], mean=0.0, std=initializer_range / math.sqrt(2 * n_layer) * 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa65b455-1d81-4ead-9e1a-4860a22c102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMBackbone(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, n_layer: int, d_inner: int, vocab_size: int,\n",
    "                 process_group=None, layer=None,\n",
    "                 attn_layer_idx=None, attn_cfg=None, max_position_embeddings=0,\n",
    "                 resid_dropout: float = 0.0, embed_dropout: float = 0.1,\n",
    "                 layer_norm_epsilon: float = 1e-5, initializer_cfg=None,residual_in_fp32=False,\n",
    "                 device=None, dtype=None, **kwargs) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.process_group = process_group\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "        # note max_position_embeddings is 0 for Hyena, and therefore isn't used\n",
    "        self.embeddings = GPT2Embeddings(d_model, vocab_size, max_position_embeddings,\n",
    "                                             **factory_kwargs)\n",
    "\n",
    "        self.layers = nn.ModuleList([create_block(\n",
    "            d_model, d_inner=d_inner,\n",
    "            layer=layer, attn_layer_idx=attn_layer_idx,\n",
    "            attn_cfg=attn_cfg, layer_norm_epsilon=layer_norm_epsilon,\n",
    "            resid_dropout1=embed_dropout if i == 0 else resid_dropout,\n",
    "            resid_dropout2=resid_dropout, residual_in_fp32=residual_in_fp32,layer_idx=i,\n",
    "            **factory_kwargs,\n",
    "        ) for i in range(n_layer)])\n",
    "\n",
    "        self.drop_f = nn.Dropout(resid_dropout)\n",
    "        self.ln_f = nn.LayerNorm(d_model, eps=layer_norm_epsilon, **factory_kwargs)\n",
    "\n",
    "        self.apply(partial(_init_weights, n_layer=n_layer,\n",
    "                           **(initializer_cfg if initializer_cfg is not None else {})))\n",
    "\n",
    "    def forward(self, input_ids, position_ids=None):\n",
    "        hidden_states = self.embeddings(input_ids, position_ids=position_ids,)\n",
    "        residual = None\n",
    "\n",
    "        for layer in self.layers:\n",
    "            hidden_states, residual = layer(hidden_states, residual)\n",
    "\n",
    "        dropped = self.drop_f(hidden_states)\n",
    "        residual = (dropped + residual) if residual is not None else dropped\n",
    "        hidden_states = self.ln_f(residual.to(dtype=self.ln_f.weight.dtype))\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05ea7c-0280-4553-9669-07dd78ac9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TokenClassificationHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        lin1_size: int,\n",
    "        lin2_size: int,\n",
    "        num_class: int ,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, lin1_size),\n",
    "            # nn.BatchNorm1d(lin1_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lin1_size, lin2_size),\n",
    "            # nn.BatchNorm1d(lin2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lin2_size, num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf0fe1-7d8f-4f60-93a7-6f11fcac3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Model (backbone + head)\n",
    "\n",
    "\"\"\"\n",
    "Putting it all together, the model consists of a backbone model\n",
    "and a decoder head (you can turn off head for embeddings only too).\n",
    "\n",
    "Here we use a simple head to do multi-classification, but\n",
    "can also swap the head to do next token prediction too.  We defer to the main\n",
    "HyenaDNA for that code, since pretraining with next token prediction isn't quite\n",
    "feasible on colab.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class HyenaDNAModel(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 n_layer: int, \n",
    "                 d_inner: int, \n",
    "                 vocab_size: int,\n",
    "                 layer=None, attn_layer_idx=None, attn_cfg=None, max_position_embeddings=0,\n",
    "                 resid_dropout: float = 0.0, embed_dropout: float = 0.1,\n",
    "                 layer_norm_epsilon: float = 1e-5, initializer_cfg=None,residual_in_fp32=False,\n",
    "                 pad_vocab_size_multiple: int = 1, \n",
    "                 n_classes: int = 2,               \n",
    "                 device=None, dtype=None, **kwargs) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        if vocab_size % pad_vocab_size_multiple != 0:\n",
    "            vocab_size += pad_vocab_size_multiple - (vocab_size % pad_vocab_size_multiple)\n",
    "\n",
    "\n",
    "        # check if layer (config) has d_model (HF code differs from main Safari code)\n",
    "        if 'd_model' not in layer:\n",
    "            layer['d_model'] = d_model\n",
    "\n",
    "        self.backbone = LMBackbone(\n",
    "            d_model=d_model, n_layer=n_layer, d_inner=d_inner, vocab_size=vocab_size,\n",
    "            layer=layer, attn_layer_idx=attn_layer_idx, attn_cfg=attn_cfg,\n",
    "            max_position_embeddings=max_position_embeddings,\n",
    "            resid_dropout=resid_dropout, embed_dropout=embed_dropout,\n",
    "            layer_norm_epsilon=layer_norm_epsilon,\n",
    "            initializer_cfg=initializer_cfg, residual_in_fp32=residual_in_fp32,\n",
    "            **factory_kwargs, **kwargs\n",
    "        )\n",
    "\n",
    "        # we only need a head if doing classification, otherwise we'll use the\n",
    "        # hidden states as embeddings\n",
    "\n",
    "        self.head = SequenceDecoder(d_model=d_model, d_output=n_classes, l_output=0, mode='pool')\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.apply(partial(_init_weights, n_layer=n_layer,\n",
    "                           **(initializer_cfg if initializer_cfg is not None else {})))\n",
    "\n",
    "        # if self.use_head:\n",
    "        #     self.tie_weights()\n",
    "\n",
    "    # def tie_weights(self):\n",
    "    #     self.head.weight = self.backbone.embeddings.word_embeddings.weight\n",
    "\n",
    "    def forward(self, input_ids, position_ids=None, state=None): # state for the repo interface\n",
    "        hidden_states = self.backbone(input_ids, position_ids=position_ids)\n",
    "\n",
    "        if self.use_head:\n",
    "            return self.head(hidden_states)\n",
    "        else:\n",
    "            return hidden_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc",
   "language": "python",
   "name": "dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
