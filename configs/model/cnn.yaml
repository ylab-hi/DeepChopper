_target_: deepchopper.models.cnn_module.LitBenchmarkCNN

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

  # number_of_classes, vocab_size, num_filters, filter_sizes, embedding_dim=100
net:
  _target_: deepchopper.models.cnn_module.BenchmarkCNN
  number_of_classes: 2
  vocab_size: 5
  num_filters: 2
  filter_sizes: 15
  embedding_dim: 100

# compile model for faster training with pytorch 2.0
compile: false
